{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTdigit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9ltEZEUl9JZ",
        "colab_type": "text"
      },
      "source": [
        "Model for SUDOKU Digit Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNTX47vVk4Fv",
        "colab_type": "code",
        "outputId": "136d7b1b-bcdf-4231-a6e0-61440ea0f675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDXRmZzVmMUN",
        "colab_type": "text"
      },
      "source": [
        "Here we will first train the model on **MNIST data** then it will be trained on our data for sudoku digit recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXW7LshUmjSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzip the file train.csv\n",
        "!unzip /content/data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2cwi6_d3Z4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2bf8a2f-62ab-4393-8026-9352e19890de"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "image = load_img('/content/rot/img001-00001.png')\n",
        "array = img_to_array(image)\n",
        "array.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rnYeARmmzoI",
        "colab_type": "code",
        "outputId": "3cba37c4-6710-4e17-e79c-f1a420c9fd03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "img_width,img_height = 28,28\n",
        "batch_size = 64\n",
        "train_data_dir = '/content/data'\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    validation_split=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    subset='training')\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size,\n",
        "    subset='validation')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8235 images belonging to 9 classes.\n",
            "Found 909 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EebPt20pMpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDWBBekyotyf",
        "colab_type": "code",
        "outputId": "8ec76961-7f46-441b-ae91-bbc5f4146190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "#Training the model\n",
        "history = model.fit_generator(train_generator,steps_per_epoch=int(train_generator.samples/64),\n",
        "                              epochs=10,validation_data=validation_generator,\n",
        "                              validation_steps=int(validation_generator.samples/64))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "128/128 [==============================] - 10s 77ms/step - loss: 0.8365 - accuracy: 0.7299 - val_loss: 1.7704 - val_accuracy: 0.3549\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 9s 68ms/step - loss: 0.2194 - accuracy: 0.9264 - val_loss: 3.2008 - val_accuracy: 0.2095\n",
            "Epoch 3/10\n",
            "128/128 [==============================] - 9s 68ms/step - loss: 0.1436 - accuracy: 0.9498 - val_loss: 0.6922 - val_accuracy: 0.7077\n",
            "Epoch 4/10\n",
            "128/128 [==============================] - 9s 68ms/step - loss: 0.1230 - accuracy: 0.9583 - val_loss: 0.0033 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "128/128 [==============================] - 9s 68ms/step - loss: 0.1033 - accuracy: 0.9648 - val_loss: 0.0373 - val_accuracy: 0.9834\n",
            "Epoch 6/10\n",
            "128/128 [==============================] - 9s 69ms/step - loss: 0.0933 - accuracy: 0.9687 - val_loss: 0.0122 - val_accuracy: 0.9988\n",
            "Epoch 7/10\n",
            "128/128 [==============================] - 9s 69ms/step - loss: 0.0733 - accuracy: 0.9745 - val_loss: 0.0785 - val_accuracy: 0.9385\n",
            "Epoch 8/10\n",
            "128/128 [==============================] - 9s 69ms/step - loss: 0.0723 - accuracy: 0.9760 - val_loss: 0.0086 - val_accuracy: 0.9941\n",
            "Epoch 9/10\n",
            "128/128 [==============================] - 9s 69ms/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.0052 - val_accuracy: 0.9680\n",
            "Epoch 10/10\n",
            "128/128 [==============================] - 9s 69ms/step - loss: 0.0647 - accuracy: 0.9780 - val_loss: 4.6566e-04 - val_accuracy: 0.9941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v72zGmsz9WO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b4379bd2-8d82-4195-ef8e-80d14ef37820"
      },
      "source": [
        "import cv2\n",
        "image = cv2.imread(\"/content/data/2/img003-00008.png\")\n",
        "image1 = cv2.imread(\"/content/data/1/img002-00007.png\")\n",
        " \n",
        "image = cv2.resize(image,(28,28),interpolation=cv2.INTER_AREA)\n",
        "image1 = cv2.resize(image1,(28,28),interpolation=cv2.INTER_AREA)\n",
        "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "image1 = cv2.cvtColor(image1,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "preds = model.predict([image.reshape(-1,28,28,1)])\n",
        "for cls in train_generator.class_indices:\n",
        "    print(\"\"+str(cls)+\": \"+str(preds[0][train_generator.class_indices[cls]]))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: 0.0\n",
            "2: 1.0\n",
            "3: 0.0\n",
            "4: 0.0\n",
            "5: 0.0\n",
            "6: 0.0\n",
            "7: 0.0\n",
            "8: 0.0\n",
            "9: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL4AYvGUKVkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('digit.model')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}